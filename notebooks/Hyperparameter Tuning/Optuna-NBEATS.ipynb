{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_target, load_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import optuna\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from darts.metrics import smape, mse\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "from darts import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(series, train_split: float, val_split: float):\n",
    "    val_len = int(len(series) * train_split)\n",
    "    test_len = int(len(series) * val_split)\n",
    "    train, val, test = series[:val_len], series[val_len:test_len], series[test_len:]\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "target_series = load_target('../../data/03_processed/on_forecourt_sessions.csv', group_cols='location_id',\n",
    "                            time_col='date', value_cols='energy_delivered_kwh', static_cols=['num_evse'], freq='D')\n",
    "covariates = load_covariates('../../data/03_processed/weather_ecad.csv', time_col='date',\n",
    "                                value_cols=['temp_max', 'temp_min', 'sunshine', 'precip'], freq='D')\n",
    "\n",
    "target_series = [series for series in target_series if len(series) == 1035]\n",
    "# Cluster Time Series\n",
    "series = concatenate(target_series, axis=1)\n",
    "\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.85\n",
    "\n",
    "train_series, val_series, test_series = train_val_test_split(series, TRAIN_SPLIT, VAL_SPLIT)\n",
    "\n",
    "# scale target\n",
    "target_scaler = Scaler(MaxAbsScaler())\n",
    "train_series = target_scaler.fit_transform(train_series)\n",
    "val_series = target_scaler.transform(val_series)\n",
    "series_transformed = target_scaler.transform(series)\n",
    "\n",
    "\n",
    "train_covariates, val_covariates, test_covariates = train_val_test_split(covariates, TRAIN_SPLIT, VAL_SPLIT)\n",
    "# scale covariate\n",
    "covariate_scaler = Scaler(MaxAbsScaler())\n",
    "train_covariates = covariate_scaler.fit_transform(train_covariates)\n",
    "val_covariates = covariate_scaler.transform(val_covariates)\n",
    "covariates_transformed = covariate_scaler.transform(covariates)\n",
    "\n",
    "train_val_series = concatenate([train_series, val_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 36)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, in_len-1)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 10)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 5)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 5)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 128, 512)\n",
    "    generic_architecture= trial.suggest_categorical(\"generic_architecture\", [False, True])\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n",
    "    include_day = trial.suggest_categorical(\"day\", [False, True])\n",
    "\n",
    "    # throughout training we'll monitor the validation loss for both pruning and early stopping\n",
    "    # pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.01, patience=3, verbose=True)\n",
    "\n",
    "    pl_trainer_kwargs = {\"callbacks\": [ early_stopper]}\n",
    "    num_workers = 0\n",
    "\n",
    "    # optionally also add the (scaled) year value as a past covariate\n",
    "    if include_day:\n",
    "        encoders = {\"datetime_attribute\": {\"past\": [\"day\"]},\n",
    "                    \"transformer\": Scaler()}\n",
    "    else:\n",
    "        encoders = None\n",
    "\n",
    "    # reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # build the TCN model\n",
    "    model = NBEATSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=32,\n",
    "        n_epochs=100,\n",
    "        nr_epochs_val_period=1,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=layer_widths,\n",
    "        generic_architecture=generic_architecture,\n",
    "        optimizer_kwargs={\"lr\": lr},\n",
    "        add_encoders=encoders,\n",
    "        likelihood=GaussianLikelihood(),\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "        model_name=\"nbeats_model\",\n",
    "        force_reset=True,\n",
    "        save_checkpoints=True,\n",
    "    )\n",
    "\n",
    "    # train the model\n",
    "    model.fit(\n",
    "        series=train_series,\n",
    "        past_covariates=covariates_transformed,\n",
    "        val_series=val_series,\n",
    "        val_past_covariates=covariates_transformed,\n",
    "        num_loader_workers=num_workers,\n",
    "    )\n",
    "\n",
    "   \n",
    "    # reload best model over course of training\n",
    "    model = NBEATSModel.load_from_checkpoint(\"nbeats_model\")\n",
    "\n",
    "    # Evaluate how good it is on the validation set, using sMAPE\n",
    "    # preds = model.predict(series=train, n=VAL_LEN)\n",
    "\n",
    "    mses = model.backtest(\n",
    "        train_val_series,\n",
    "        start=val_series.start_time(),\n",
    "        forecast_horizon=1,\n",
    "        stride=1,\n",
    "        last_points_only=False,\n",
    "        retrain=False,\n",
    "        verbose=True,\n",
    "        metric=mse\n",
    "    )\n",
    "    mse_val = np.mean(mses)\n",
    "\n",
    "    return mse_val if mse_val != np.nan else float(\"inf\")\n",
    "\n",
    "\n",
    "# for convenience, print some optimization trials information\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n",
    "\n",
    "\n",
    "# optimize hyperparameters by minimizing the sMAPE on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_day</th>\n",
       "      <th>params_generic_architecture</th>\n",
       "      <th>params_in_len</th>\n",
       "      <th>params_layer_widths</th>\n",
       "      <th>params_lr</th>\n",
       "      <th>params_num_blocks</th>\n",
       "      <th>params_num_layers</th>\n",
       "      <th>params_num_stacks</th>\n",
       "      <th>params_out_len</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.116408</td>\n",
       "      <td>2023-05-24 11:45:49.339026</td>\n",
       "      <td>2023-05-24 11:46:56.856573</td>\n",
       "      <td>0 days 00:01:07.517547</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     value             datetime_start          datetime_complete  \\\n",
       "0       0  0.116408 2023-05-24 11:45:49.339026 2023-05-24 11:46:56.856573   \n",
       "\n",
       "                duration  params_day  params_generic_architecture  \\\n",
       "0 0 days 00:01:07.517547       False                        False   \n",
       "\n",
       "   params_in_len  params_layer_widths  params_lr  params_num_blocks  \\\n",
       "0             15                  168   0.000232                  1   \n",
       "\n",
       "   params_num_layers  params_num_stacks  params_out_len     state  \n",
       "0                  5                  4              13  COMPLETE  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = study.trials_dataframe()\n",
    "results[results['value'] == results['value'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
