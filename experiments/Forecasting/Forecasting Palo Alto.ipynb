{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../src'))\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ShellDataset, PaloAltoDataset, BoulderDataset\n",
    "from visualization import plot_time_series_predictions\n",
    "from evaluation import evaluate, print_metrics_table\n",
    "from models import train_predict, train_predict_past_covariates, train_predict_global, train_predict_global_past_covariates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_HORIZON = 30\n",
    "INPUT_CHUNK_LENGTH = 30\n",
    "USE_COVARIATES = False\n",
    "TRAIN_DATA = 240 # 8 months\n",
    "TEST_DATA = 90 # 3 months"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import PaloAltoDataset\n",
    "series_dataset = PaloAltoDataset()\n",
    "series = series_dataset.load(subset=None, train_length=TRAIN_DATA, test_length=TEST_DATA, na_threshold=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform splits\n",
    "series_scaler = Scaler(MinMaxScaler())\n",
    "series_train = series_scaler.fit_transform(series['train'])\n",
    "series_test= series_scaler.transform(series['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models.forecasting.baselines import NaiveMean\n",
    "def load_baselinemodel():\n",
    "    return NaiveMean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_baseline = []\n",
    "for series_train_single, series_test_single in zip(series_train, series_test):\n",
    "    model = load_baselinemodel()\n",
    "\n",
    "    forecast = train_predict(model, \n",
    "                        series_train=series_train_single, \n",
    "                        series_test=series_test_single, \n",
    "                        horizon=FORECAST_HORIZON, \n",
    "                        retrain=True)\n",
    "    \n",
    "    predictions_baseline.append(forecast)\n",
    "predictions_baseline = series_scaler.inverse_transform(predictions_baseline)\n",
    "predictions['Baseline'] = predictions_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predictions['Baseline'], series['test'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arimamodel():\n",
    "    from darts.models import ARIMA\n",
    "    return ARIMA(\n",
    "        p=INPUT_CHUNK_LENGTH,\n",
    "        d=0,\n",
    "        q=INPUT_CHUNK_LENGTH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "predictions_arima = []\n",
    "for series_train_single, series_test_single in zip(series_train, series_test):\n",
    "    model = load_arimamodel()\n",
    "\n",
    "    forecast = train_predict(model, \n",
    "                        series_train=series_train_single, \n",
    "                        series_test=series_test_single, \n",
    "                        horizon=FORECAST_HORIZON, \n",
    "                        retrain=False)\n",
    "    \n",
    "    predictions_arima.append(forecast)\n",
    "predictions_arima = series_scaler.inverse_transform(predictions_arima)\n",
    "predictions['ARIMA'] = predictions_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predictions['ARIMA'], series['test'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import TransformerModel\n",
    "\n",
    "def load_transformermodel():\n",
    "    return TransformerModel(\n",
    "        nr_epochs_val_period=1,\n",
    "        nhead=8,\n",
    "        num_encoder_layers=1,\n",
    "        num_decoder_layers=1,\n",
    "        dim_feedforward=128,\n",
    "        input_chunk_length=INPUT_CHUNK_LENGTH,\n",
    "        output_chunk_length=FORECAST_HORIZON,\n",
    "        random_state=0,\n",
    "        # add_encoders=past_datetime_encoder,\n",
    "        pl_trainer_kwargs={\"callbacks\": [EarlyStopping(monitor=\"val_loss\", patience=10, min_delta=0.01, mode='min')], \"log_every_n_steps\": 1},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_transformer = []\n",
    "for series_train_single, series_test_single in zip(series_train, series_test):\n",
    "    model = load_transformermodel()\n",
    "\n",
    "    forecast = train_predict(model,\n",
    "                        series_train=series_train_single,\n",
    "                        series_test=series_test_single,\n",
    "                        horizon=FORECAST_HORIZON,\n",
    "                        train_split=0.7,\n",
    "                        retrain=False)\n",
    "    \n",
    "    predictions_transformer.append(forecast)\n",
    "predictions_transformer = series_scaler.inverse_transform(predictions_transformer)\n",
    "predictions['Transformer'] = predictions_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predictions['Transformer'], series['test'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NHITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import NHiTSModel\n",
    "\n",
    "def load_nhitsmodel():\n",
    "    return NHiTSModel(\n",
    "        nr_epochs_val_period=1,\n",
    "        input_chunk_length=INPUT_CHUNK_LENGTH,\n",
    "        output_chunk_length=FORECAST_HORIZON,\n",
    "        random_state=0,\n",
    "        # add_encoders=past_datetime_encoder,\n",
    "        pl_trainer_kwargs={\"callbacks\": [EarlyStopping(monitor=\"val_loss\", patience=10, min_delta=0.01, mode='min')], \"log_every_n_steps\": 1},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "predictions_nhits = []\n",
    "for series_train_single, series_test_single in zip(series_train, series_test):\n",
    "    model = load_nhitsmodel()\n",
    "\n",
    "    forecast = train_predict(model,\n",
    "                        series_train=series_train_single,\n",
    "                        series_test=series_test_single,\n",
    "                        horizon=FORECAST_HORIZON,\n",
    "                        train_split=0.7,\n",
    "                        retrain=False)\n",
    "    \n",
    "    predictions_nhits.append(forecast)\n",
    "predictions_nhits = series_scaler.inverse_transform(predictions_nhits)\n",
    "predictions['NHiTS (Local)'] = predictions_nhits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predictions['NHiTS (Local)'], series['test'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nhits_model = load_nhitsmodel()\n",
    "nhits_model_fit, predictions_nhits_global = train_predict_global(\n",
    "                                                            model=nhits_model, \n",
    "                                                            series_train=series_train, \n",
    "                                                            series_test=series_test, \n",
    "                                                            horizon=FORECAST_HORIZON, \n",
    "                                                            train_split=0.7, \n",
    "                                                            retrain=False\n",
    "                                                        )\n",
    "\n",
    "predictions_nhits_global = series_scaler.inverse_transform(predictions_nhits_global)\n",
    "predictions['NHiTS (Global)'] = predictions_nhits_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predictions['NHiTS (Global)'], series['test'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_COVARIATES=False,FORECAST_HORIZON=30,INPUT_CHUNK_LENGTH=30,TRAIN_DATA=240,TEST_DATA=90, PaloAltoDataset,len(series['train'])=5,len(series['test'])=5)\n",
      "Model: Baseline {'RMSE': 20.462021543932487, 'MAE': 16.923750190321115, 'MAPE': 51.12169589727189}\n",
      "Model: ARIMA {'RMSE': 22.534036509077534, 'MAE': 18.48633199913444, 'MAPE': 63.49173629662278}\n",
      "Model: Transformer {'RMSE': 23.593278165470426, 'MAE': 18.630191290781603, 'MAPE': 74.28062022938342}\n",
      "Model: NHiTS (Local) {'RMSE': 22.930195769389506, 'MAE': 17.57614113671096, 'MAPE': 82.0298672837002}\n",
      "Model: NHiTS (Global) {'RMSE': 23.789759200014323, 'MAE': 17.944163916861, 'MAPE': 75.82736653769766}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{USE_COVARIATES=},{FORECAST_HORIZON=},{INPUT_CHUNK_LENGTH=},{TRAIN_DATA=},{TEST_DATA=}, {series_dataset.__class__.__name__},{len(series['train'])=},{len(series['test'])=})\")\n",
    "for model, model_predictions in predictions.items():\n",
    "    results = evaluate(model_predictions, series['test'])\n",
    "    print(f\"Model:\", model, results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series_predictions(predictions, series['test'], FORECAST_HORIZON)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
